# Complicated examples
You can easily write a concurrent web scraper with grugstream. 
Here's an example of crawling from one website recursively for 1000 link:

```python
{!docs/crawler.py!}
```
